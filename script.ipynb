{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faf49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, requests, re, html5lib, os\n",
    "from datetime import date, timedelta, datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcde386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinksPartidas(Bsoup):\n",
    "    # dado uma página de partidas \"Bsoup\" do vlr.gg, pega o link de cada partida\n",
    "    # no formato 'https://www.vlr.gg/'+links[i]\n",
    "    # detalhe que a função inverte a ordem das partidas, pra pegar da mais antiga pra mais nova\n",
    "    linksnovo_pro_antigo = []\n",
    "    links = []\n",
    "    for tag in Bsoup.find_all('a', href = True):\n",
    "        try:\n",
    "            if int(tag['href'][1]):\n",
    "                linksnovo_pro_antigo.append(tag['href'])\n",
    "        except:\n",
    "            #print('url pulada: ', tag['href'])\n",
    "            pass\n",
    "    for i in range(len(linksnovo_pro_antigo)):\n",
    "        links.append(linksnovo_pro_antigo[len(linksnovo_pro_antigo)-1-i])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfecd24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheguei na pag.  4\n",
      "cheguei na pag.  3\n",
      "cheguei na pag.  2\n",
      "https://www.vlr.gg/286738/arf-team-vs-alter-ego-predator-league-indonesia-2024-lf\n",
      "(11, 58)\n",
      "https://www.vlr.gg/285174/reckoning-esports-vs-true-rippers-the-esports-club-the-arena-championship-2023-gf\n",
      "(22, 72)\n",
      "https://www.vlr.gg/286656/made-in-thailand-vs-fancy-united-esports-afreecatv-valorant-league-3rd-place\n",
      "(33, 72)\n",
      "https://www.vlr.gg/286739/boom-esports-vs-arf-team-predator-league-indonesia-2024-gf\n",
      "(44, 72)\n",
      "https://www.vlr.gg/286657/full-sense-vs-xerxia-esports-afreecatv-valorant-league-gf\n",
      "(55, 86)\n",
      "https://www.vlr.gg/285298/ovation-esports-vs-alternate-attax-valorant-challengers-2023-dach-arcade-playoffs-lr1\n",
      "(66, 86)\n",
      "https://www.vlr.gg/286837/carameloo-vs-meraki-spike-ladies-vii-pl-sf\n",
      "(77, 86)\n",
      "https://www.vlr.gg/286838/erin-e-amigas-vs-eu-e-minhas-mana-spike-ladies-vii-pl-sf\n",
      "(88, 86)\n",
      "https://www.vlr.gg/286708/e-xolos-lazer-vs-gaming-up-cross-fire-latin-america-north-playoffs-gf\n",
      "(99, 86)\n",
      "cheguei na pag.  1\n",
      "https://www.vlr.gg/287311/supernova-galaxy-vs-dreamland-the-cozy-clash-lr6\n",
      "(110, 86)\n",
      "https://www.vlr.gg/287310/mfs-vs-flyquest-red-the-cozy-clash-lr6\n",
      "(121, 86)\n",
      "2023-11-19 completo\n",
      "cheguei na pag.  4\n",
      "cheguei na pag.  3\n",
      "cheguei na pag.  2\n",
      "cheguei na pag.  1\n",
      "https://www.vlr.gg/285021/dragon-ranger-gaming-vs-lgd-gaming-china-evolution-series-act-3-heritability-lr1\n",
      "(11, 44)\n",
      "https://www.vlr.gg/285022/funplus-phoenix-vs-17gaming-china-evolution-series-act-3-heritability-lr1\n",
      "(22, 44)\n",
      "https://www.vlr.gg/285017/trace-esports-vs-rare-atom-china-evolution-series-act-3-heritability-ubsf\n",
      "(34, 58)\n",
      "https://www.vlr.gg/284652/onyx-ravens-vs-nasr-esports-connecta-the-ultimate-battle-playoffs-gf\n",
      "(45, 58)\n",
      "2023-11-20 completo\n",
      "cheguei na pag.  4\n",
      "cheguei na pag.  3\n",
      "cheguei na pag.  2\n",
      "cheguei na pag.  1\n",
      "https://www.vlr.gg/285023/top-esports-vs-royal-never-give-up-china-evolution-series-act-3-heritability-lr1\n",
      "(11, 44)\n",
      "https://www.vlr.gg/285024/bilibili-gaming-vs-titan-esports-club-china-evolution-series-act-3-heritability-lr1\n",
      "(22, 44)\n",
      "https://www.vlr.gg/285018/attacking-soul-esports-vs-edward-gaming-china-evolution-series-act-3-heritability-ubsf\n",
      "(33, 58)\n",
      "2023-11-21 completo\n",
      "cheguei na pag.  4\n",
      "cheguei na pag.  3\n",
      "cheguei na pag.  2\n",
      "cheguei na pag.  1\n",
      "https://www.vlr.gg/287473/team-snakes-vs-aussie-underdog-red-bull-campus-clutch-2023-world-finals-f\n",
      "(11, 30)\n",
      "https://www.vlr.gg/287467/gyudon-eating-vs-socks-up-red-bull-campus-clutch-2023-world-finals-e\n",
      "(22, 30)\n",
      "https://www.vlr.gg/287475/team-snakes-vs-krc-genk-esports-red-bull-campus-clutch-2023-world-finals-f\n",
      "(33, 30)\n",
      "https://www.vlr.gg/287469/gyudon-eating-vs-bubatzbuben-red-bull-campus-clutch-2023-world-finals-e\n",
      "(44, 30)\n",
      "https://www.vlr.gg/287471/gyudon-eating-vs-gumk-i-red-bull-campus-clutch-2023-world-finals-e\n",
      "(55, 30)\n",
      "https://www.vlr.gg/285026/dragon-ranger-gaming-vs-funplus-phoenix-china-evolution-series-act-3-heritability-lr2\n",
      "(66, 44)\n",
      "https://www.vlr.gg/287479/mcd-cashiers-vs-st-clair-saints-red-bull-campus-clutch-2023-world-finals-g\n",
      "(77, 44)\n",
      "https://www.vlr.gg/285025/top-esports-vs-titan-esports-club-china-evolution-series-act-3-heritability-lr2\n",
      "(88, 44)\n",
      "https://www.vlr.gg/287481/mcd-cashiers-vs-novo-cc-red-bull-campus-clutch-2023-world-finals-g\n",
      "(99, 44)\n",
      "https://www.vlr.gg/287484/st-clair-saints-vs-novo-cc-red-bull-campus-clutch-2023-world-finals-g\n",
      "(110, 44)\n",
      "https://www.vlr.gg/287658/team-maryna-vs-team-mle-flyquest-trailblazer-tournament-november-sf\n",
      "(121, 44)\n",
      "https://www.vlr.gg/287657/team-starriebun-vs-team-tiffae-flyquest-trailblazer-tournament-november-sf\n",
      "(132, 58)\n",
      "https://www.vlr.gg/287659/team-starriebun-vs-team-maryna-flyquest-trailblazer-tournament-november-gf\n",
      "(143, 58)\n",
      "2023-11-22 completo\n",
      "cheguei na pag.  4\n",
      "cheguei na pag.  3\n",
      "cheguei na pag.  2\n",
      "cheguei na pag.  1\n",
      "https://www.vlr.gg/287613/team-snakes-vs-los-vigentes-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(11, 44)\n",
      "https://www.vlr.gg/287612/garuda-vs-bubatzbuben-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(22, 44)\n",
      "https://www.vlr.gg/287611/narodni-garda-vs-przejazd-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(33, 44)\n",
      "https://www.vlr.gg/287610/nemapau-vs-isp-n-enjoyers-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(44, 58)\n",
      "https://www.vlr.gg/287617/gumk-i-vs-valiant-pbl-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(55, 58)\n",
      "https://www.vlr.gg/287616/retiredgamers-vs-aussie-underdog-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(66, 58)\n",
      "https://www.vlr.gg/287615/st-clair-saints-vs-vac-kimchi-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(77, 58)\n",
      "https://www.vlr.gg/287614/werder-weremem-vs-zen-esports-red-bull-campus-clutch-2023-world-finals-ro16\n",
      "(88, 58)\n",
      "https://www.vlr.gg/285028/attacking-soul-esports-vs-funplus-phoenix-china-evolution-series-act-3-heritability-lr3\n",
      "(99, 58)\n",
      "https://www.vlr.gg/285027/trace-esports-vs-titan-esports-club-china-evolution-series-act-3-heritability-lr3\n",
      "(110, 58)\n",
      "https://www.vlr.gg/287618/isp-n-enjoyers-vs-narodni-garda-red-bull-campus-clutch-2023-world-finals-qf\n",
      "(121, 58)\n",
      "https://www.vlr.gg/287619/garuda-vs-team-snakes-red-bull-campus-clutch-2023-world-finals-qf\n",
      "(132, 58)\n",
      "https://www.vlr.gg/287621/retiredgamers-vs-valiant-pbl-red-bull-campus-clutch-2023-world-finals-qf\n",
      "(143, 58)\n",
      "https://www.vlr.gg/287620/zen-esports-vs-st-clair-saints-red-bull-campus-clutch-2023-world-finals-qf\n",
      "(154, 58)\n",
      "2023-11-23 completo\n"
     ]
    }
   ],
   "source": [
    "def encontrar_data(Bsoup, data_pegar, Links):\n",
    "    for dia in Bsoup('div', class_='wf-label mod-large'):\n",
    "        data = dia.text.replace(' ', '').replace('\\n', '').replace('\\t', '')\n",
    "        if data[-5:] == 'Today':\n",
    "            data = data[:-5]\n",
    "        elif data[-9:] == 'Yesterday':\n",
    "            data = data[:-9]\n",
    "        data = datetime.strptime(data, '%a,%B%d,%Y').date()\n",
    "\n",
    "        if data >= data_pegar:\n",
    "            return 1, 0\n",
    "\n",
    "    return 0, len(Links)\n",
    "    \n",
    "\n",
    "\n",
    "def salvar_csv(data_pegar):\n",
    "    df = pd.DataFrame()\n",
    "    url = 'https://www.vlr.gg/matches/results/'\n",
    "    url_pag = 'https://www.vlr.gg/matches/results/?page='\n",
    "\n",
    "    # # garante que pega todas as partidas de ontem, com folga\n",
    "    pagina_inicial = 4\n",
    "    nome_col = 0\n",
    "    passei_da_data=0\n",
    "\n",
    "    for k in range(pagina_inicial, 0, -1): \n",
    "        if passei_da_data:\n",
    "            break\n",
    "        print('cheguei na pag. ', str(k))\n",
    "        matches_page = requests.get(url_pag + str(k))\n",
    "        Bsoup = BeautifulSoup(matches_page.text, 'html.parser')\n",
    "        Links = LinksPartidas(Bsoup)\n",
    "        m = 0\n",
    "        comeco = 0\n",
    "        while m < len(Links):\n",
    "            if comeco == 0:\n",
    "                comeco, m = encontrar_data(Bsoup, data_pegar, Links)\n",
    "                \n",
    "            variavel = m\n",
    "            \n",
    "            for h in range(variavel,len(Links)):\n",
    "                match_url = 'https://www.vlr.gg' + Links[h]\n",
    "                match_soup = BeautifulSoup(requests.get(match_url).text, 'html.parser')\n",
    "                data_partida = (datetime.strptime(\n",
    "                                match_soup('div', class_ = 'moment-tz-convert')[0]\n",
    "                                .get('data-utc-ts'), \"%Y-%m-%d %H:%M:%S\")\n",
    "                                .date())\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    if (match_soup('div', class_ = 'wf-title-med')[0].text.find('TBD') == -1 and\n",
    "                            match_soup('div', class_ = 'wf-title-med')[1].text.find('TBD') == -1 and\n",
    "                            match_soup('div', class_ = 'vm-stats-container')[0].text.find('No data available for this match') == -1 and\n",
    "                            len(match_soup('tbody')[2]('tr')[0]('td')[1]('div')[0].contents) > 1 and\n",
    "                            data_partida >= data_pegar):\n",
    "                            #and\n",
    "                            #match_soup('tbody')[2]('tr')[0]('td')[3]('span')[1].text != ' ' and\n",
    "                            #match_soup('tbody')[3]('tr')[0]('td')[3]('span')[1].text != ' '):\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "                m += 1\n",
    "            \n",
    "            \n",
    "            if m >= len(Links):\n",
    "                break\n",
    "            \n",
    "            data_partida = (datetime.strptime(\n",
    "                                match_soup('div', class_ = 'moment-tz-convert')[0]\n",
    "                                .get('data-utc-ts'), \"%Y-%m-%d %H:%M:%S\")\n",
    "                                .date())\n",
    "\n",
    "            if data_partida > data_pegar:\n",
    "                passei_da_data=1\n",
    "                print(str(data_pegar), 'completo')\n",
    "                break\n",
    "\n",
    "            print(match_url)\n",
    "            panda = pd.read_html(match_url)        \n",
    "            temp = pd.concat([panda[2], panda[3]], ignore_index=True)\n",
    "            \n",
    "            try:\n",
    "                temp2 = {'scores_team_1':[int(match_soup('div', class_ = 'js-spoiler')[0]('span')[0].text)] ,\n",
    "                        'scores_team_2':[int(match_soup('div', class_ = 'js-spoiler')[0]('span')[2].text)]}\n",
    "            except:\n",
    "                temp2 = {'scores_team_1' : [], 'scores_team_2' : []}\n",
    "                print('erro placar pag: ', k)\n",
    "                pass\n",
    "            for i in range(0, len(panda)-2, 2):\n",
    "                temp2['scores_team_1'].append(int(match_soup('div', class_ = 'score')[i].text))\n",
    "                temp2['scores_team_2'].append(int(match_soup('div', class_ = 'score')[i+1].text))\n",
    "                \n",
    "            temp2 = pd.DataFrame(temp2)\n",
    "            temp = pd.concat([temp, temp2], axis = 1)\n",
    "            \n",
    "            if nome_col == 0:\n",
    "                colunas_v = panda[2].columns.tolist()\n",
    "                colunas_n = [[],[],[],[],[]]\n",
    "                for coluna in colunas_v:\n",
    "                    colunas_n[0].append('Map 1'+coluna)\n",
    "                    colunas_n[1].append('Map 2'+coluna)\n",
    "                    colunas_n[2].append('Map 3'+coluna)\n",
    "                    colunas_n[3].append('Map 4'+coluna)\n",
    "                    colunas_n[4].append('Map 5'+coluna)\n",
    "                nome_col += 1\n",
    "                \n",
    "            panda[0].rename(columns = dict(zip(colunas_v, colunas_n[0])), inplace = True)\n",
    "            panda[1].rename(columns = dict(zip(colunas_v, colunas_n[0])), inplace = True)\n",
    "            \n",
    "            temp = pd.concat([temp, pd.concat([panda[0], panda[1]], ignore_index=True)], axis = 1)\n",
    "            for j in range(4, len(panda), 2):\n",
    "                panda[j].rename(columns = dict(zip(colunas_v, colunas_n[j//2-1])), inplace = True)\n",
    "                panda[j+1].rename(columns = dict(zip(colunas_v, colunas_n[j//2-1])), inplace = True)\n",
    "                temp = pd.concat([temp, pd.concat([panda[j], panda[j+1]], ignore_index=True)], axis = 1)\n",
    "            \n",
    "            df = pd.concat([df, temp], ignore_index = True)\n",
    "            df = pd.concat([df, pd.DataFrame(np.full(df.shape[1], np.nan)[None], columns = df.columns)])\n",
    "            print(df.shape)\n",
    "\n",
    "            m += 1\n",
    "        \n",
    "    df.to_csv(f'jogos_por_dia\\\\{str(data_pegar)}.csv')\n",
    "\n",
    "    return\n",
    "            \n",
    "# # pegar partidas desta data, ou seja, ontem\n",
    "data_pegar = date.today() - timedelta(days = 1)\n",
    "\n",
    "# # olhar pra ultima partida que esse script pegou\n",
    "proxima_data = datetime.strptime(os.listdir('jogos_por_dia')[-1][:-4], '%Y-%m-%d').date() + timedelta(days=1)\n",
    "\n",
    "if proxima_data == data_pegar:\n",
    "    salvar_csv(data_pegar)\n",
    "elif proxima_data < data_pegar:\n",
    "    dias = data_pegar - proxima_data\n",
    "    while dias != timedelta(days=0):\n",
    "        salvar_csv(proxima_data)\n",
    "        proxima_data+= timedelta(days=1)\n",
    "        dias-= timedelta(days=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
